{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DeepHedging_RL2.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install stable-baselines3\n",
    "!pip install -U pyyaml"
   ],
   "metadata": {
    "id": "vcF1L6CvWbkS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b713b5ce-7094-4246-b7e4-cde986dcca06"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stable-baselines3\n",
      "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
      "\u001B[K     |████████████████████████████████| 177 kB 5.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (3.2.2)\n",
      "Collecting gym==0.21\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.5 MB 51.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.11.0+cu113)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.21.6)\n",
      "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3) (2022.1)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616827 sha256=f674929db01c5b5d60d2de0b8500f1c461c74b7200f098713a2fd984f035d630\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
      "Successfully built gym\n",
      "Installing collected packages: gym, stable-baselines3\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.17.3\n",
      "    Uninstalling gym-0.17.3:\n",
      "      Successfully uninstalled gym-0.17.3\n",
      "Successfully installed gym-0.21.0 stable-baselines3-1.5.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 4.6 MB/s \n",
      "\u001B[?25hInstalling collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed pyyaml-6.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsSmH_rqVNb2",
    "outputId": "69d8c970-64a2-44ff-e461-3b7a61bf2aca"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Deep_Hedging'...\n",
      "remote: Enumerating objects: 1218, done.\u001B[K\n",
      "remote: Counting objects: 100% (1218/1218), done.\u001B[K\n",
      "remote: Compressing objects: 100% (814/814), done.\u001B[K\n",
      "remote: Total 1218 (delta 445), reused 1110 (delta 337), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (1218/1218), 5.17 MiB | 24.30 MiB/s, done.\n",
      "Resolving deltas: 100% (445/445), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/bluesunb/Deep_Hedging.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -rf Deep_Hedging/Algorithms/learn/logs/trash"
   ],
   "metadata": {
    "id": "aXqNJ4wRyB3K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! mv Deep_Hedging/* ./"
   ],
   "metadata": {
    "id": "4r2ifVQHciIh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -rf Deep_Hedging"
   ],
   "metadata": {
    "id": "qTmpPiA3Syf8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cd Algorithms/learn/sac/"
   ],
   "metadata": {
    "id": "ld9Q_731cMqD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from Algorithms.ddpg import config"
   ],
   "metadata": {
    "id": "RPspHclFW01K"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Plot Setting"
   ],
   "metadata": {
    "id": "sGaMoAu-jk4b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import seaborn as sb\n",
    "import matplotlib\n",
    "\n",
    "sb.set_style('darkgrid')\n",
    "\n",
    "FONTSIZE = 10\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 100\n",
    "matplotlib.rcParams[\"figure.titlesize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"legend.fontsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"xtick.labelsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"ytick.labelsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"axes.labelsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"axes.titlesize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "matplotlib.rcParams[\"savefig.pad_inches\"] = 0.1\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2\n",
    "matplotlib.rcParams[\"axes.linewidth\"] = 1.6"
   ],
   "metadata": {
    "id": "yXXufGhjJ0LQ"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Model Setting"
   ],
   "metadata": {
    "id": "clmbZaQajs7U"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Load config"
   ],
   "metadata": {
    "id": "r2IVZwLKju6g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "env_kwargs, model_kwargs, learn_kwargs = config.load_config('Algorithms/learn/ddpg/tmp_config.yaml')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLy3xh-0kRTt",
    "outputId": "0fe7d66a-0363-448f-edca-59593d125f5f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env 'BSMarket was created!\n",
      "env 'BSMarket was created!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from Env.buffers import CustomDictReplayBuffer\n",
    "\n",
    "ntb_mode = True    #@param {type:\"boolean\"}\n",
    "double_ddpg = True  #@param {type:\"boolean\"}\n",
    "\n",
    "random_drift = True #@param {type:\"boolean\"}\n",
    "random_vol = False  #@param {type:\"boolean\"}\n",
    "\n",
    "drift = 0.0 #@param [\"0.0\", \"0.4\", \"0.6\", \"0.8\", \"1.2\", \"1.6\"] {type:\"raw\"}\n",
    "volatility = 0.2    #@param [\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"] {type:\"raw\"}\n",
    "n_assets = 2000\n",
    "env_kwargs.update({\n",
    "    'n_assets': n_assets,\n",
    "    'drift': drift,\n",
    "    'volatility': volatility,\n",
    "    'cost': 0.01,\n",
    "    'reward_fn': 'mean var',\n",
    "    'reward_fn_kwargs': {},\n",
    "    'reward_mode': 'pnl',\n",
    "    'random_drift': random_drift,\n",
    "    'random_vol': random_vol,\n",
    "    'ntb_mode': ntb_mode\n",
    "})\n",
    "\n",
    "def lr_schedule(left: float):\n",
    "    return 6e-4 * (0.1 ** (1 - left ** 2))\n",
    "\n",
    "model_kwargs.update({\n",
    "    'replay_buffer_class': CustomDictReplayBuffer,\n",
    "    'buffer_size': 300,\n",
    "    'learning_starts': 300,\n",
    "    'learning_rate': lr_schedule,\n",
    "    'batch_size': 30,\n",
    "    'mean_coeff': 1.0,\n",
    "    'std_coeff': 1.0,\n",
    "    'gradient_steps': 15,\n",
    "})\n",
    "\n",
    "model_kwargs['policy_kwargs'].update({\n",
    "    'ntb_mode': ntb_mode,\n",
    "    'double_ddpg': double_ddpg,\n",
    "    'n_critics': 1\n",
    "})\n",
    "\n",
    "model_kwargs['policy_kwargs']['features_extractor_kwargs'].update({\n",
    "    'features_in': 4 if ntb_mode else 5\n",
    "})\n",
    "\n",
    "learn_kwargs.update({\n",
    "    'total_timesteps': 3000\n",
    "})\n",
    "\n",
    "# del model_kwargs['std_coeff']\n",
    "\n",
    "actor_net_kwargs = {'bn_kwargs': {'num_features': env_kwargs['n_assets']}}\n",
    "critic_net_kwargs = {'bn_kwargs': {'num_features': env_kwargs['n_assets']}}\n",
    "if ntb_mode:\n",
    "    model_kwargs['policy_kwargs'].update({\n",
    "        'net_arch': [],\n",
    "        # 'actor_net_kwargs': actor_net_kwargs,\n",
    "        # 'critic_net_kwargs': critic_net_kwargs,\n",
    "    })\n",
    "\n",
    "    model_kwargs['policy_kwargs']['features_extractor_kwargs'].update({\n",
    "        'features_out': 32,\n",
    "        'net_arch': [32,]\n",
    "    })\n",
    "\n",
    "else:\n",
    "    model_kwargs['policy_kwargs'].update({\n",
    "        'net_arch': [],\n",
    "    })\n",
    "\n",
    "    model_kwargs['policy_kwargs']['features_extractor_kwargs'].update({\n",
    "        'features_out': 2,\n",
    "        'net_arch': [32, 64]\n",
    "    })\n",
    "\n",
    "model_kwargs['policy_kwargs']['one_asset'] = (env_kwargs['n_assets']==1)"
   ],
   "metadata": {
    "id": "eAJ_0AUsplAa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config.reconstruct_config(env_kwargs, model_kwargs, learn_kwargs)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmiRBx-apn4Q",
    "outputId": "62a4f115-324e-4baa-9453-8e91fa08351f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env 'BSMarket was created!\n",
      "model_kwargs['env']: <BSMarket instance>\n",
      "env 'BSMarket was created!\n",
      "learn_kwargs['eval_env']: <BSMarketEval instance>\n",
      "learn_kwargs['tb_log_name']: ddpg_220622-0825\n",
      "learn_kwargs['eval_log_path']: ../logs/tb_logs/d8v2/d10v2/ddpg_220622-0825_1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pprint(env_kwargs, indent=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqKGzZwmj2ZY",
    "outputId": "8f80d7f7-6291-4d6b-bf37-969c4d99ef53"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'cost': 0.02,\n",
      " 'dividend': 0.0,\n",
      " 'drift': 1.0,\n",
      " 'freq': 1,\n",
      " 'gen_name': 'gbm',\n",
      " 'init_price': 1.0,\n",
      " 'maturity': 30,\n",
      " 'n_assets': 1000,\n",
      " 'payoff': 'european',\n",
      " 'payoff_coeff': 1.0,\n",
      " 'period_unit': 365,\n",
      " 'random_drift': False,\n",
      " 'random_vol': False,\n",
      " 'reward_fn': 'mean var',\n",
      " 'reward_fn_kwargs': {},\n",
      " 'reward_mode': 'pnl',\n",
      " 'risk_free_interest': 0.0,\n",
      " 'strike': 1.0,\n",
      " 'volatility': 0.2}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pprint(model_kwargs)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kr6c7c7dhra",
    "outputId": "5953f193-ebf6-4a18-b778-136ba5f175a3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'action_noise': NormalActionNoise(mu=0.0, sigma=0.1),\n",
      " 'batch_size': 15,\n",
      " 'buffer_size': 300,\n",
      " 'create_eval_env': False,\n",
      " 'device': 'auto',\n",
      " 'env': <Env.env.BSMarket object at 0x7fd252b414d0>,\n",
      " 'gamma': 0.99,\n",
      " 'gradient_steps': -1,\n",
      " 'learning_rate': <function lr_schedule at 0x7fd240a1fa70>,\n",
      " 'learning_starts': 300,\n",
      " 'mean_coeff': 1.0,\n",
      " 'optimize_memory_usage': False,\n",
      " 'policy': <class 'Algorithms.ddpg.policies.DoubleDDPGPolicy'>,\n",
      " 'policy_kwargs': {'activation_fn': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "                   'actor_net_kwargs': {'bn_kwargs': {'num_features': 1000}},\n",
      "                   'critic_net_kwargs': {'bn_kwargs': {'num_features': 1000}},\n",
      "                   'double_ddpg': True,\n",
      "                   'features_extractor_class': <class 'Env.feature_extractor.MarketObsExtractor'>,\n",
      "                   'features_extractor_kwargs': {'activation_fn': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "                                                 'features_in': 4,\n",
      "                                                 'features_out': 64,\n",
      "                                                 'flat_obs': False,\n",
      "                                                 'last_activation_fn': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "                                                 'net_arch': [32]},\n",
      "                   'n_critics': 2,\n",
      "                   'net_arch': {'pi': [(<class 'torch.nn.modules.batchnorm.BatchNorm1d'>,\n",
      "                                        'bn'),\n",
      "                                       32,\n",
      "                                       32],\n",
      "                                'qf': [(<class 'torch.nn.modules.batchnorm.BatchNorm1d'>,\n",
      "                                        'bn'),\n",
      "                                       16],\n",
      "                                'qf2': [(<class 'torch.nn.modules.batchnorm.BatchNorm1d'>,\n",
      "                                         'bn'),\n",
      "                                        4]},\n",
      "                   'normalize_images': False,\n",
      "                   'ntb_mode': True,\n",
      "                   'one_asset': False,\n",
      "                   'optimizer_class': <class 'torch.optim.adam.Adam'>,\n",
      "                   'optimizer_kwargs': None,\n",
      "                   'share_features_extractor': True},\n",
      " 'replay_buffer_class': <class 'Env.buffers.CustomDictReplayBuffer'>,\n",
      " 'replay_buffer_kwargs': {},\n",
      " 'seed': 42,\n",
      " 'std_coeff': 1.0,\n",
      " 'tau': 0.005,\n",
      " 'tensorboard_log': '../logs/tb_logs/d8v2/d10v2',\n",
      " 'train_freq': (1, 'episode'),\n",
      " 'verbose': 1}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pprint(learn_kwargs)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpM5xG6Sdx2N",
    "outputId": "4c67fda8-8937-4589-a880-a03a87ff3fd1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'callback': <Algorithms.ddpg.callbacks.ReportCallbacks object at 0x7fd241fbc890>,\n",
      " 'eval_env': <Env.env.BSMarketEval object at 0x7fd252c3d8d0>,\n",
      " 'eval_freq': 30,\n",
      " 'eval_log_path': '../logs/tb_logs/d8v2/d10v2/ddpg_220622-0822_1',\n",
      " 'log_interval': 30,\n",
      " 'n_eval_episodes': 1,\n",
      " 'reset_num_timesteps': True,\n",
      " 'tb_log_name': 'ddpg_220622-0822',\n",
      " 'total_timesteps': 2000}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.1 Env prices check"
   ],
   "metadata": {
    "collapsed": false,
    "id": "F1OowCurI4qW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Construct env, model"
   ],
   "metadata": {
    "id": "_CesRCyQnsNi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from Algorithms.ddpg import DoubleDDPG\n",
    "\n",
    "print(f'double_ddpg: {double_ddpg}')\n",
    "if double_ddpg:\n",
    "    model = DoubleDDPG(**model_kwargs)\n",
    "else:\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "id": "jUW6brePd0Ee",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dabed75b-2bbc-4951-ba7a-f00b3c3703cf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "double_ddpg: True\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.policy"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nExPeSqkwpqy",
    "outputId": "b9c405b2-438d-48d7-ce2d-f513b05fb196"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DoubleDDPGPolicy(\n",
       "  (actor): CustomActor(\n",
       "    (features_extractor): MarketObsExtractor(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (mu): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=32, out_features=2, bias=True)\n",
       "      (6): Tanh()\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "  )\n",
       "  (actor_target): CustomActor(\n",
       "    (features_extractor): MarketObsExtractor(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (mu): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Linear(in_features=32, out_features=2, bias=True)\n",
       "      (6): Tanh()\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "  )\n",
       "  (critic): CustomContinuousCritic(\n",
       "    (features_extractor): MarketObsExtractor(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic_target): CustomContinuousCritic(\n",
       "    (features_extractor): MarketObsExtractor(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=16, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic2): CustomContinuousCritic(\n",
       "    (features_extractor): MarketObsExtractor(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=4, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=4, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=4, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=4, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic2_target): CustomContinuousCritic(\n",
       "    (features_extractor): MarketObsExtractor(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=4, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=4, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=4, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=65, out_features=4, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=4, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 341
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Learning"
   ],
   "metadata": {
    "id": "FmVia8sCn6Vw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ../logs/tb_logs/d8v2/d10v2/ddpg_220622-0825_1\n",
      "[Training Start]\n",
      "Eval num_timesteps=30, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0249  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=60, episode_reward=-0.03 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0251  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60       |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0243  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=120, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0248  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 120      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=150, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0246  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 150      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0248  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 180      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=210, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0249  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 210      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0245  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 240      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=270, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0249  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 270      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0245  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 300      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=330, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0248  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 330      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=360, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0225  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 360      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.913    |\n",
      "|    action_std      | 0.989    |\n",
      "|    actor_loss      | 0.318    |\n",
      "|    critic2_loss    | 0.0124   |\n",
      "|    critic_loss     | 0.0185   |\n",
      "|    learning_rate   | 0.000996 |\n",
      "|    mean_cost_loss  | -0.292   |\n",
      "|    n_updates       | 30       |\n",
      "|    std_cost_loss   | 0.0267   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=390, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0223  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 390      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.938    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.327    |\n",
      "|    critic2_loss    | 0.002    |\n",
      "|    critic_loss     | 0.00483  |\n",
      "|    learning_rate   | 0.000941 |\n",
      "|    mean_cost_loss  | -0.293   |\n",
      "|    n_updates       | 60       |\n",
      "|    std_cost_loss   | 0.0343   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=420, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0219  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 420      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.94     |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.313    |\n",
      "|    critic2_loss    | 0.00194  |\n",
      "|    critic_loss     | 0.00556  |\n",
      "|    learning_rate   | 0.000889 |\n",
      "|    mean_cost_loss  | -0.286   |\n",
      "|    n_updates       | 90       |\n",
      "|    std_cost_loss   | 0.0271   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=450, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 450      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.949    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.307    |\n",
      "|    critic2_loss    | 0.00171  |\n",
      "|    critic_loss     | 0.00472  |\n",
      "|    learning_rate   | 0.000842 |\n",
      "|    mean_cost_loss  | -0.282   |\n",
      "|    n_updates       | 120      |\n",
      "|    std_cost_loss   | 0.0255   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=480, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0212  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 480      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.955    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.305    |\n",
      "|    critic2_loss    | 0.00205  |\n",
      "|    critic_loss     | 0.00619  |\n",
      "|    learning_rate   | 0.000797 |\n",
      "|    mean_cost_loss  | -0.28    |\n",
      "|    n_updates       | 150      |\n",
      "|    std_cost_loss   | 0.0251   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=510, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 510      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.958    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.311    |\n",
      "|    critic2_loss    | 0.00127  |\n",
      "|    critic_loss     | 0.00365  |\n",
      "|    learning_rate   | 0.000756 |\n",
      "|    mean_cost_loss  | -0.286   |\n",
      "|    n_updates       | 180      |\n",
      "|    std_cost_loss   | 0.0249   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=540, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0214  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 540      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.961    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.31     |\n",
      "|    critic2_loss    | 0.0012   |\n",
      "|    critic_loss     | 0.00369  |\n",
      "|    learning_rate   | 0.000718 |\n",
      "|    mean_cost_loss  | -0.286   |\n",
      "|    n_updates       | 210      |\n",
      "|    std_cost_loss   | 0.0244   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=570, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0219  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 570      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.965    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.31     |\n",
      "|    critic2_loss    | 0.00156  |\n",
      "|    critic_loss     | 0.00491  |\n",
      "|    learning_rate   | 0.000682 |\n",
      "|    mean_cost_loss  | -0.286   |\n",
      "|    n_updates       | 240      |\n",
      "|    std_cost_loss   | 0.0239   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=600, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 600      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.966    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.306    |\n",
      "|    critic2_loss    | 0.00155  |\n",
      "|    critic_loss     | 0.00515  |\n",
      "|    learning_rate   | 0.000649 |\n",
      "|    mean_cost_loss  | -0.283   |\n",
      "|    n_updates       | 270      |\n",
      "|    std_cost_loss   | 0.0229   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=630, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0219  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 630      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.303    |\n",
      "|    critic2_loss    | 0.00197  |\n",
      "|    critic_loss     | 0.00618  |\n",
      "|    learning_rate   | 0.000618 |\n",
      "|    mean_cost_loss  | -0.281   |\n",
      "|    n_updates       | 300      |\n",
      "|    std_cost_loss   | 0.0221   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=660, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 660      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.31     |\n",
      "|    critic2_loss    | 0.00112  |\n",
      "|    critic_loss     | 0.00331  |\n",
      "|    learning_rate   | 0.000589 |\n",
      "|    mean_cost_loss  | -0.287   |\n",
      "|    n_updates       | 330      |\n",
      "|    std_cost_loss   | 0.0234   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=690, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 690      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.307    |\n",
      "|    critic2_loss    | 0.00136  |\n",
      "|    critic_loss     | 0.0042   |\n",
      "|    learning_rate   | 0.000562 |\n",
      "|    mean_cost_loss  | -0.284   |\n",
      "|    n_updates       | 360      |\n",
      "|    std_cost_loss   | 0.0227   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=720, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.973    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.3      |\n",
      "|    critic2_loss    | 0.00176  |\n",
      "|    critic_loss     | 0.00538  |\n",
      "|    learning_rate   | 0.000537 |\n",
      "|    mean_cost_loss  | -0.278   |\n",
      "|    n_updates       | 390      |\n",
      "|    std_cost_loss   | 0.0221   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=750, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.022   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 750      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.309    |\n",
      "|    critic2_loss    | 0.00128  |\n",
      "|    critic_loss     | 0.00371  |\n",
      "|    learning_rate   | 0.000514 |\n",
      "|    mean_cost_loss  | -0.285   |\n",
      "|    n_updates       | 420      |\n",
      "|    std_cost_loss   | 0.0237   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=780, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 780      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.306    |\n",
      "|    critic2_loss    | 0.00144  |\n",
      "|    critic_loss     | 0.00404  |\n",
      "|    learning_rate   | 0.000492 |\n",
      "|    mean_cost_loss  | -0.282   |\n",
      "|    n_updates       | 450      |\n",
      "|    std_cost_loss   | 0.0234   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=810, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 810      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.301    |\n",
      "|    critic2_loss    | 0.0018   |\n",
      "|    critic_loss     | 0.00514  |\n",
      "|    learning_rate   | 0.000471 |\n",
      "|    mean_cost_loss  | -0.278   |\n",
      "|    n_updates       | 480      |\n",
      "|    std_cost_loss   | 0.023    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=840, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.022   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 840      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.305    |\n",
      "|    critic2_loss    | 0.00114  |\n",
      "|    critic_loss     | 0.00318  |\n",
      "|    learning_rate   | 0.000452 |\n",
      "|    mean_cost_loss  | -0.281   |\n",
      "|    n_updates       | 510      |\n",
      "|    std_cost_loss   | 0.0239   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=870, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0219  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 870      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.968    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.304    |\n",
      "|    critic2_loss    | 0.00146  |\n",
      "|    critic_loss     | 0.00403  |\n",
      "|    learning_rate   | 0.000434 |\n",
      "|    mean_cost_loss  | -0.28    |\n",
      "|    n_updates       | 540      |\n",
      "|    std_cost_loss   | 0.0241   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=900, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 900      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.966    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.303    |\n",
      "|    critic2_loss    | 0.00125  |\n",
      "|    critic_loss     | 0.00339  |\n",
      "|    learning_rate   | 0.000417 |\n",
      "|    mean_cost_loss  | -0.279   |\n",
      "|    n_updates       | 570      |\n",
      "|    std_cost_loss   | 0.024    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.109   |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 36       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 900      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=930, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0214  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 930      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.967    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.294    |\n",
      "|    critic2_loss    | 0.00225  |\n",
      "|    critic_loss     | 0.00606  |\n",
      "|    learning_rate   | 0.000401 |\n",
      "|    mean_cost_loss  | -0.271   |\n",
      "|    n_updates       | 600      |\n",
      "|    std_cost_loss   | 0.023    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=960, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 960      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.299    |\n",
      "|    critic2_loss    | 0.00177  |\n",
      "|    critic_loss     | 0.00475  |\n",
      "|    learning_rate   | 0.000387 |\n",
      "|    mean_cost_loss  | -0.275   |\n",
      "|    n_updates       | 630      |\n",
      "|    std_cost_loss   | 0.0238   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=990, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0213  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 990      |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.297    |\n",
      "|    critic2_loss    | 0.00174  |\n",
      "|    critic_loss     | 0.00458  |\n",
      "|    learning_rate   | 0.000373 |\n",
      "|    mean_cost_loss  | -0.273   |\n",
      "|    n_updates       | 660      |\n",
      "|    std_cost_loss   | 0.0238   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1020, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0213  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1020     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.299    |\n",
      "|    critic2_loss    | 0.00167  |\n",
      "|    critic_loss     | 0.00432  |\n",
      "|    learning_rate   | 0.00036  |\n",
      "|    mean_cost_loss  | -0.275   |\n",
      "|    n_updates       | 690      |\n",
      "|    std_cost_loss   | 0.0241   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1050, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1050     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.999    |\n",
      "|    actor_loss      | 0.296    |\n",
      "|    critic2_loss    | 0.00171  |\n",
      "|    critic_loss     | 0.00442  |\n",
      "|    learning_rate   | 0.000348 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 720      |\n",
      "|    std_cost_loss   | 0.0239   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1080, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.022   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1080     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.29     |\n",
      "|    critic2_loss    | 0.00202  |\n",
      "|    critic_loss     | 0.00516  |\n",
      "|    learning_rate   | 0.000336 |\n",
      "|    mean_cost_loss  | -0.267   |\n",
      "|    n_updates       | 750      |\n",
      "|    std_cost_loss   | 0.0232   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1110, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0213  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1110     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.296    |\n",
      "|    critic2_loss    | 0.00137  |\n",
      "|    critic_loss     | 0.00344  |\n",
      "|    learning_rate   | 0.000326 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 780      |\n",
      "|    std_cost_loss   | 0.0243   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1140, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1140     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.294    |\n",
      "|    critic2_loss    | 0.00165  |\n",
      "|    critic_loss     | 0.00412  |\n",
      "|    learning_rate   | 0.000316 |\n",
      "|    mean_cost_loss  | -0.27    |\n",
      "|    n_updates       | 810      |\n",
      "|    std_cost_loss   | 0.024    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1170, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1170     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.294    |\n",
      "|    critic2_loss    | 0.00149  |\n",
      "|    critic_loss     | 0.00375  |\n",
      "|    learning_rate   | 0.000306 |\n",
      "|    mean_cost_loss  | -0.27    |\n",
      "|    n_updates       | 840      |\n",
      "|    std_cost_loss   | 0.0239   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1200, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1200     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.296    |\n",
      "|    critic2_loss    | 0.00125  |\n",
      "|    critic_loss     | 0.00306  |\n",
      "|    learning_rate   | 0.000297 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 870      |\n",
      "|    std_cost_loss   | 0.0245   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1230, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1230     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.287    |\n",
      "|    critic2_loss    | 0.00223  |\n",
      "|    critic_loss     | 0.0055   |\n",
      "|    learning_rate   | 0.000289 |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 900      |\n",
      "|    std_cost_loss   | 0.023    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1260, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0212  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1260     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.297    |\n",
      "|    critic2_loss    | 0.000841 |\n",
      "|    critic_loss     | 0.00202  |\n",
      "|    learning_rate   | 0.000281 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 930      |\n",
      "|    std_cost_loss   | 0.0249   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1290, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1290     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.296    |\n",
      "|    critic2_loss    | 0.00111  |\n",
      "|    critic_loss     | 0.00269  |\n",
      "|    learning_rate   | 0.000274 |\n",
      "|    mean_cost_loss  | -0.271   |\n",
      "|    n_updates       | 960      |\n",
      "|    std_cost_loss   | 0.0247   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1320, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1320     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.288    |\n",
      "|    critic2_loss    | 0.00198  |\n",
      "|    critic_loss     | 0.00475  |\n",
      "|    learning_rate   | 0.000267 |\n",
      "|    mean_cost_loss  | -0.265   |\n",
      "|    n_updates       | 990      |\n",
      "|    std_cost_loss   | 0.0235   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1350, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1350     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.286    |\n",
      "|    critic2_loss    | 0.00218  |\n",
      "|    critic_loss     | 0.00527  |\n",
      "|    learning_rate   | 0.000261 |\n",
      "|    mean_cost_loss  | -0.263   |\n",
      "|    n_updates       | 1020     |\n",
      "|    std_cost_loss   | 0.0233   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1380, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0213  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1380     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.293    |\n",
      "|    critic2_loss    | 0.00132  |\n",
      "|    critic_loss     | 0.00317  |\n",
      "|    learning_rate   | 0.000255 |\n",
      "|    mean_cost_loss  | -0.269   |\n",
      "|    n_updates       | 1050     |\n",
      "|    std_cost_loss   | 0.0244   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1410, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1410     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.289    |\n",
      "|    critic2_loss    | 0.00153  |\n",
      "|    critic_loss     | 0.00361  |\n",
      "|    learning_rate   | 0.00025  |\n",
      "|    mean_cost_loss  | -0.265   |\n",
      "|    n_updates       | 1080     |\n",
      "|    std_cost_loss   | 0.0237   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1440, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1440     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.288    |\n",
      "|    critic2_loss    | 0.00161  |\n",
      "|    critic_loss     | 0.00385  |\n",
      "|    learning_rate   | 0.000244 |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 1110     |\n",
      "|    std_cost_loss   | 0.0237   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1470, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1470     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.287    |\n",
      "|    critic2_loss    | 0.00197  |\n",
      "|    critic_loss     | 0.00472  |\n",
      "|    learning_rate   | 0.00024  |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 1140     |\n",
      "|    std_cost_loss   | 0.0236   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1500, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1500     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.281    |\n",
      "|    critic2_loss    | 0.00243  |\n",
      "|    critic_loss     | 0.00578  |\n",
      "|    learning_rate   | 0.000235 |\n",
      "|    mean_cost_loss  | -0.258   |\n",
      "|    n_updates       | 1170     |\n",
      "|    std_cost_loss   | 0.0227   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1530, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1530     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.968    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.286    |\n",
      "|    critic2_loss    | 0.00171  |\n",
      "|    critic_loss     | 0.00401  |\n",
      "|    learning_rate   | 0.000231 |\n",
      "|    mean_cost_loss  | -0.262   |\n",
      "|    n_updates       | 1200     |\n",
      "|    std_cost_loss   | 0.0235   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1560, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0214  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1560     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.286    |\n",
      "|    critic2_loss    | 0.00184  |\n",
      "|    critic_loss     | 0.00425  |\n",
      "|    learning_rate   | 0.000227 |\n",
      "|    mean_cost_loss  | -0.262   |\n",
      "|    n_updates       | 1230     |\n",
      "|    std_cost_loss   | 0.0237   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1590, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.022   |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1590     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.283    |\n",
      "|    critic2_loss    | 0.00234  |\n",
      "|    critic_loss     | 0.00548  |\n",
      "|    learning_rate   | 0.000224 |\n",
      "|    mean_cost_loss  | -0.259   |\n",
      "|    n_updates       | 1260     |\n",
      "|    std_cost_loss   | 0.0231   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1620, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1620     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.968    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.288    |\n",
      "|    critic2_loss    | 0.00138  |\n",
      "|    critic_loss     | 0.00319  |\n",
      "|    learning_rate   | 0.00022  |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 1290     |\n",
      "|    std_cost_loss   | 0.0242   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1650, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1650     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.288    |\n",
      "|    critic2_loss    | 0.00133  |\n",
      "|    critic_loss     | 0.00302  |\n",
      "|    learning_rate   | 0.000217 |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 1320     |\n",
      "|    std_cost_loss   | 0.024    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1680, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0214  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1680     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.283    |\n",
      "|    critic2_loss    | 0.00208  |\n",
      "|    critic_loss     | 0.00483  |\n",
      "|    learning_rate   | 0.000215 |\n",
      "|    mean_cost_loss  | -0.259   |\n",
      "|    n_updates       | 1350     |\n",
      "|    std_cost_loss   | 0.0233   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1710, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0214  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1710     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.973    |\n",
      "|    action_std      | 0.999    |\n",
      "|    actor_loss      | 0.289    |\n",
      "|    critic2_loss    | 0.000777 |\n",
      "|    critic_loss     | 0.0017   |\n",
      "|    learning_rate   | 0.000212 |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 1380     |\n",
      "|    std_cost_loss   | 0.0242   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1740, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1740     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.973    |\n",
      "|    action_std      | 0.999    |\n",
      "|    actor_loss      | 0.282    |\n",
      "|    critic2_loss    | 0.00187  |\n",
      "|    critic_loss     | 0.00425  |\n",
      "|    learning_rate   | 0.00021  |\n",
      "|    mean_cost_loss  | -0.259   |\n",
      "|    n_updates       | 1410     |\n",
      "|    std_cost_loss   | 0.0231   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1770, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1770     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.973    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.283    |\n",
      "|    critic2_loss    | 0.00194  |\n",
      "|    critic_loss     | 0.00446  |\n",
      "|    learning_rate   | 0.000208 |\n",
      "|    mean_cost_loss  | -0.26    |\n",
      "|    n_updates       | 1440     |\n",
      "|    std_cost_loss   | 0.0233   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1800, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1800     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.282    |\n",
      "|    critic2_loss    | 0.00204  |\n",
      "|    critic_loss     | 0.00465  |\n",
      "|    learning_rate   | 0.000206 |\n",
      "|    mean_cost_loss  | -0.259   |\n",
      "|    n_updates       | 1470     |\n",
      "|    std_cost_loss   | 0.0233   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.0749  |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 1800     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1830, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1830     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.97     |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.282    |\n",
      "|    critic2_loss    | 0.00167  |\n",
      "|    critic_loss     | 0.00378  |\n",
      "|    learning_rate   | 0.000205 |\n",
      "|    mean_cost_loss  | -0.259   |\n",
      "|    n_updates       | 1500     |\n",
      "|    std_cost_loss   | 0.0233   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1860, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0214  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1860     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.284    |\n",
      "|    critic2_loss    | 0.00159  |\n",
      "|    critic_loss     | 0.00348  |\n",
      "|    learning_rate   | 0.000203 |\n",
      "|    mean_cost_loss  | -0.261   |\n",
      "|    n_updates       | 1530     |\n",
      "|    std_cost_loss   | 0.0236   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1890, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1890     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.287    |\n",
      "|    critic2_loss    | 0.000993 |\n",
      "|    critic_loss     | 0.00223  |\n",
      "|    learning_rate   | 0.000202 |\n",
      "|    mean_cost_loss  | -0.262   |\n",
      "|    n_updates       | 1560     |\n",
      "|    std_cost_loss   | 0.0242   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1920, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1920     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.969    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.285    |\n",
      "|    critic2_loss    | 0.00137  |\n",
      "|    critic_loss     | 0.00312  |\n",
      "|    learning_rate   | 0.000201 |\n",
      "|    mean_cost_loss  | -0.261   |\n",
      "|    n_updates       | 1590     |\n",
      "|    std_cost_loss   | 0.0236   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1950, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1950     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.971    |\n",
      "|    action_std      | 0.997    |\n",
      "|    actor_loss      | 0.282    |\n",
      "|    critic2_loss    | 0.00164  |\n",
      "|    critic_loss     | 0.00372  |\n",
      "|    learning_rate   | 0.000201 |\n",
      "|    mean_cost_loss  | -0.258   |\n",
      "|    n_updates       | 1620     |\n",
      "|    std_cost_loss   | 0.0232   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1980, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1980     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.285    |\n",
      "|    critic2_loss    | 0.00123  |\n",
      "|    critic_loss     | 0.00277  |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    mean_cost_loss  | -0.261   |\n",
      "|    n_updates       | 1650     |\n",
      "|    std_cost_loss   | 0.0239   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=2010, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0217  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 2010     |\n",
      "| train/             |          |\n",
      "|    action_mean     | 0.972    |\n",
      "|    action_std      | 0.998    |\n",
      "|    actor_loss      | 0.284    |\n",
      "|    critic2_loss    | 0.0013   |\n",
      "|    critic_loss     | 0.00293  |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    mean_cost_loss  | -0.261   |\n",
      "|    n_updates       | 1680     |\n",
      "|    std_cost_loss   | 0.0238   |\n",
      "---------------------------------\n",
      "[Training End]  steps: 0\ttimes: 68.6204731464386\n"
     ]
    }
   ],
   "source": [
    "model = model.learn(**learn_kwargs)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMfUmt5KI4qZ",
    "outputId": "c05a7a77-53fe-4a80-f016-456a574fdf1f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config.save_config(learn_kwargs['eval_log_path']+'/config.yaml', env_kwargs, model_kwargs, learn_kwargs)"
   ],
   "metadata": {
    "id": "jovGDkEAOPp4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f1f452aa-1077-404c-f809-a3fc73154e10"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<BSMarket instance> will be save as name. env_kwargs not in kwargs!\n",
      "<BSMarketEval instance> will be save as name. eval_env_kwargs not in kwargs!\n",
      "<Algorithms.ddpg.callbacks.ReportCallbacks object at 0x7fd241fbc890> will be save as name. callback_kwargs not in kwargs!\n",
      "../logs/tb_logs/d8v2/d10v2/ddpg_220622-0825_1/config.yaml was saved.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. P&L Evaluation"
   ],
   "metadata": {
    "id": "Cg3CkZI6qakB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Load Best Model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9na6owGlI4qa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# model = model.load('../logs/tb_logs/d4v2/ddpg_220622-0746_1_NTB'+'/best_model')\n",
    "model = model.load(learn_kwargs['eval_log_path'] + '/best_model')\n",
    "print(learn_kwargs['eval_log_path'] + '/best_model')"
   ],
   "metadata": {
    "id": "qbOShZRswEgH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3a883fc9-82f7-4818-f402-0e0212f0160b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../logs/tb_logs/d8v2/d10v2/ddpg_220622-0825_1/best_model\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 eval_env setting"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Dc4yReucI4qb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "eval_env = learn_kwargs['eval_env']\n",
    "eval_env.reward_mode = 'pnl'\n",
    "# eval_env.drift = 0.0\n",
    "eval_env.random_drift = False\n",
    "eval_env.random_vol = False\n",
    "\n",
    "print(eval_env.drift, eval_env.volatility)"
   ],
   "metadata": {
    "id": "P3bcdJouqZJ-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99b1f849-761f-4aa0-aa11-4332d664f4b9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0 0.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "eval_env.drift, eval_env.volatility, eval_env.random_drift, eval_env.random_vol"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwsiOvLgMb4K",
    "outputId": "0d67b0f1-9780-4c67-f991-88e9e23e4c63"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.0, 0.2, False, False)"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Calc P&L"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wVcVhPFII4qc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.1 Zero, Random, Delta P&L"
   ],
   "metadata": {
    "collapsed": false,
    "id": "cmkfEPYxI4qc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Tmp:\n",
    "    def predict(self, obs, deterministic=False):\n",
    "        return np.zeros(1000), None\n",
    "\n",
    "class Tmp2:\n",
    "    def predict(self, obs, deterministic=False):\n",
    "        return np.ones(1000), None\n",
    "\n",
    "tmp = Tmp()\n",
    "tmp2 = Tmp2()\n",
    "zero_pnl = eval_env.eval(tmp, 'pnl', 100)\n",
    "one_pnl = eval_env.eval(tmp2, 'pnl', 100)\n",
    "random_pnl = eval_env.eval(None, 'pnl', 100)\n",
    "delta_pnl = eval_env.delta_eval('pnl', 100)"
   ],
   "metadata": {
    "id": "_z_Rh4Ztvq9o"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.2 RL, NTB P&L"
   ],
   "metadata": {
    "collapsed": false,
    "id": "I_Bj10KsI4qd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'NTB: {ntb_mode}')\n",
    "if ntb_mode:\n",
    "    ntb_pnl = eval_env.eval(model, 'pnl', 100)\n",
    "else:\n",
    "    rl_pnl = eval_env.eval(model, 'pnl', 100)"
   ],
   "metadata": {
    "id": "Bh44K7_UmUwL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a0e5c177-cb70-46b0-d7d5-0fb0a152ea95"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NTB: True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "A9DrKUfmI4qh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def pnl_reward(pnl):\n",
    "    mean = np.mean(pnl)\n",
    "    std = np.std(pnl)\n",
    "    return [mean - 0.02 * std , mean, std]\n",
    "\n",
    "def sharpe_ratio(pnl):\n",
    "    return pnl.mean()/pnl.std()\n",
    "\n",
    "def var(pnl, ratio):\n",
    "    losses = np.sort(-pnl)\n",
    "    boundary = int(np.ceil(losses.shape[-1]*ratio))\n",
    "    return losses[boundary]\n",
    "\n",
    "def cvar(pnl, ratio=0.95):\n",
    "    losses = np.sort(-pnl)\n",
    "    boundary = int(np.ceil(losses.shape[-1]*ratio))\n",
    "    return np.mean(losses[boundary:], axis=-1)"
   ],
   "metadata": {
    "id": "HYzrTOT3v10F"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4.1 Trainig Result Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OShdwK17I4qh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sb_kwargs = {'shade': True,\n",
    "              'alpha': 0.4,\n",
    "            #  'clip': (-0.04, -0.02)\n",
    "             }\n",
    "\n",
    "plt.title(rf'P&L ($\\mu$={eval_env.drift}, $\\sigma$={eval_env.volatility})')\n",
    "plt.xlabel(rf'P&L')\n",
    "if ntb_mode:\n",
    "    sb.kdeplot(ntb_pnl,**sb_kwargs, label='DDPG+NTB')\n",
    "sb.kdeplot(rl_pnl, **sb_kwargs, label='DDPG')\n",
    "sb.kdeplot(zero_pnl,**sb_kwargs, label='zero')\n",
    "sb.kdeplot(one_pnl,**sb_kwargs, label='one')\n",
    "# sb.kdeplot(random_pnl,**sb_kwargs, label='random')\n",
    "sb.kdeplot(delta_pnl,**sb_kwargs, label='delta')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n",
    "\n",
    "if ntb_mode:\n",
    "    print(f'ntb pnl: \\t\\t{np.round(pnl_reward(ntb_pnl), 4)}')\n",
    "print(f'rl pnl: \\t\\t{np.round(pnl_reward(rl_pnl), 4)}')\n",
    "print(f'zero pnl: \\t\\t{np.round(pnl_reward(zero_pnl), 4)}')\n",
    "print(f'one pnl: \\t\\t{np.round(pnl_reward(one_pnl), 4)}')\n",
    "print(f'random pnl: \\t\\t{np.round(pnl_reward(random_pnl), 4)}')\n",
    "print(f'delta pnl: \\t\\t{np.round(pnl_reward(delta_pnl), 4)}')\n",
    "print()\n",
    "\n",
    "if ntb_mode:\n",
    "    print(f'ntb cvar:\\t\\t{cvar(ntb_pnl):.5f}')\n",
    "print(f'rl cvar:\\t\\t{cvar(rl_pnl):.5f}')\n",
    "print(f'zero cvar:\\t\\t{cvar(zero_pnl):.5f}')\n",
    "print(f'one cvar:\\t\\t{cvar(one_pnl):.5f}')\n",
    "print(f'random cvar:\\t\\t{cvar(random_pnl):.5f}')\n",
    "print(f'delta cvar:\\t\\t{cvar(delta_pnl):.5f}')\n",
    "print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "iCCuwgWHnV5g",
    "outputId": "a5f2da0e-31c0-4761-d9d0-5888edf19ce3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ntb pnl: \t\t[-0.0217 -0.0217  0.0008]\n",
      "rl pnl: \t\t[-0.0379 -0.0379  0.0022]\n",
      "zero pnl: \t\t[-0.0648 -0.0647  0.0059]\n",
      "one pnl: \t\t[-0.0209 -0.0209  0.0008]\n",
      "random pnl: \t\t[-0.2447 -0.2446  0.0048]\n",
      "delta pnl: \t\t[-0.0363 -0.0363  0.0016]\n",
      "\n",
      "ntb cvar:\t\t0.02356\n",
      "rl cvar:\t\t0.04231\n",
      "zero cvar:\t\t0.07675\n",
      "one cvar:\t\t0.02292\n",
      "random cvar:\t\t0.25520\n",
      "delta cvar:\t\t0.03991\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4.2 TensorBoard"
   ],
   "metadata": {
    "id": "HZcWd2UoLhvw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5 Save, Load P&L"
   ],
   "metadata": {
    "collapsed": false,
    "id": "uq7N6eyJI4qd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.5.1 Save"
   ],
   "metadata": {
    "collapsed": false,
    "id": "jZ5iTMHbI4qe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not ntb_mode:\n",
    "    if random_drift:\n",
    "        rl_pnls = []\n",
    "        for i in range(5):\n",
    "            eval_env.drift = 0.25 * i\n",
    "            eval_env.volatility = 0.2\n",
    "            # eval_env.volatility = 0.2 + 0.2*i\n",
    "            print(eval_env.drift, eval_env.volatility)\n",
    "            rl_pnls.append(eval_env.eval(model, 'pnl', 50))\n",
    "\n",
    "    elif random_vol:\n",
    "        rl_pnls_vol = []\n",
    "        for i in range(5):\n",
    "            eval_env.drift = 0.0\n",
    "            eval_env.volatility = 0.2 + 0.2*i\n",
    "            print(eval_env.drift, eval_env.volatility)\n",
    "            rl_pnls_vol.append(eval_env.eval(model, 'pnl', 50))\n",
    "\n",
    "else:\n",
    "    if random_drift:\n",
    "        ntb_pnls = []\n",
    "        for i in range(5):\n",
    "            eval_env.drift = 0.25 * i\n",
    "            eval_env.volatility = 0.2\n",
    "            # eval_env.volatility = 0.2 + 0.2*i\n",
    "            print(eval_env.drift, eval_env.volatility)\n",
    "            ntb_pnls.append(eval_env.eval(model, 'pnl', 50))\n",
    "\n",
    "    if random_vol:\n",
    "        ntb_pnls_vol = []\n",
    "        for i in range(5):\n",
    "            eval_env.drift = 0.0\n",
    "            eval_env.volatility = 0.2 + 0.2*i\n",
    "            print(eval_env.drift, eval_env.volatility)\n",
    "            ntb_pnls_vol.append(eval_env.eval(model, 'pnl', 50))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb_kwargs = {'shade': True,\n",
    "              'alpha': 0.4,\n",
    "            #  'clip': (-0.04, -0.02)\n",
    "             }\n",
    "\n",
    "# plt.title(rf'P&L Result of DDPG ($\\mu$={eval_env.drift})')\n",
    "plt.title(rf'P&L Result of DDPG ($\\sigma$={0.2})')\n",
    "plt.xlabel(rf'P&L')\n",
    "\n",
    "for i in range(5):\n",
    "    sb.kdeplot(rl_pnls[i], **sb_kwargs, label=rf'$\\mu$={0.5*i}')\n",
    "    # sb.kdeplot(rl_pnls[i], **sb_kwargs, label=rf'$\\sigma$={0.2+0.2*i:.1f}')\n",
    "    print(np.round(pnl_reward(rl_pnls[i]), 4))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "[-0.0004 -0.0001  0.0123]\n",
    "[-0.0324 -0.0322  0.0136]\n",
    "[-0.0683 -0.068   0.0152]\n",
    "[-0.1075 -0.1072  0.0161]\n",
    "[-0.149  -0.1486  0.017 ]\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb_kwargs = {'shade': True,\n",
    "              'alpha': 0.4,\n",
    "            #  'clip': (-0.04, -0.02)\n",
    "             }\n",
    "\n",
    "plt.title(rf'P&L Result of DDPG ($\\mu$={0.0})')\n",
    "plt.xlabel(rf'P&L')\n",
    "\n",
    "for i in range(5):\n",
    "    sb.kdeplot(rl_pnls_vol[i], **sb_kwargs, label=rf'$\\sigma$={0.2*i+0.2:.1f}')\n",
    "    print(np.round(pnl_reward(rl_pnls_vol[i]), 4))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "[-0.0004 -0.0001  0.0123]\n",
    "[-0.0002  0.0003  0.0249]\n",
    "[-0.0004  0.0004  0.0389]\n",
    "[-0.002  -0.001   0.0527]\n",
    "[-0.0036 -0.0022  0.0679]\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb_kwargs = {'shade': True,\n",
    "              'alpha': 0.4,\n",
    "            #  'clip': (-0.04, -0.02)\n",
    "             }\n",
    "\n",
    "# plt.title(rf'P&L Result of NTB ($\\mu$={eval_env.drift})')\n",
    "plt.title(rf'P&L Result of NTB ($\\sigma$={0.2})')\n",
    "plt.xlabel(rf'P&L')\n",
    "\n",
    "for i in range(5):\n",
    "    sb.kdeplot(ntb_pnls[i], **sb_kwargs, label=rf'$\\mu$={0.5*i}')\n",
    "    # sb.kdeplot(ntb_pnls[i], **sb_kwargs, label=rf'$\\sigma$={0.2+0.2*i:.1f}')\n",
    "    print(np.round(pnl_reward(ntb_pnls[i]), 4))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "[-0.0168 -0.0168  0.0021]\n",
    "[-0.0146 -0.0146  0.0017]\n",
    "[-0.0139 -0.0138  0.0013]\n",
    "[-0.014 -0.014  0.001]\n",
    "[-0.0149 -0.0149  0.0009]\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb_kwargs = {'shade': True,\n",
    "              'alpha': 0.4,\n",
    "            #  'clip': (-0.04, -0.02)\n",
    "             }\n",
    "\n",
    "plt.title(rf'P&L Result of NTB ($\\mu$={0.0})')\n",
    "plt.xlabel(rf'P&L')\n",
    "\n",
    "for i in range(5):\n",
    "    # sb.kdeplot(ntb_pnls[i], **sb_kwargs, label=rf'$\\mu$={0.5*i}')\n",
    "    sb.kdeplot(ntb_pnls_vol[i], **sb_kwargs, label=rf'$\\sigma$={0.2+0.2*i:.1f}')\n",
    "    print(np.round(pnl_reward(ntb_pnls_vol[i]), 4))\n",
    "\n",
    "plt.legend()\n",
    "\"\"\"\n",
    "[-0.0002 -0.0001  0.0049]\n",
    "[0.     0.0002 0.0101]\n",
    "[-0.0001  0.0003  0.0158]\n",
    "[-0.0007 -0.0003  0.0219]\n",
    "[-0.0013 -0.0008  0.0285]\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# xrange = np.arange(0.2, 1.2, 0.2)\n",
    "xrange = np.arange(0.0, 1.2, 0.25)\n",
    "\n",
    "# plt.title(rf'Mean of P&L ($\\mu$={eval_env.drift})')\n",
    "plt.title(rf'Mean of P&L ($\\sigma$={0.2})')\n",
    "plt.plot(xrange, list(map(np.mean, rl_pnls)), 'o-', label='DDPG')\n",
    "plt.plot(xrange, list(map(np.mean, ntb_pnls)), 'o-', label='NTB')\n",
    "# plt.xlabel('volatility')\n",
    "plt.xlabel('drift')\n",
    "plt.xticks(xrange)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# xrange = np.arange(0.2, 1.2, 0.2)\n",
    "xrange = np.arange(0.0, 1.2, 0.25)\n",
    "\n",
    "# plt.title(rf'CVaR(95%) of P&L ($\\mu$={eval_env.drift})')\n",
    "plt.title(rf'CVaR(95%) of P&L ($\\sigma$={0.2})')\n",
    "plt.plot(xrange, list(map(cvar, rl_pnls)), 'o-', label='DDPG')\n",
    "plt.plot(xrange, list(map(cvar, ntb_pnls)), 'o-', label='NTB')\n",
    "# plt.xlabel('volatility')\n",
    "plt.xlabel('drift')\n",
    "plt.xticks(xrange)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xrange = np.arange(0.0, 1.2, 0.25)\n",
    "\n",
    "# plt.title(rf'Mean of P&L ($\\mu$={eval_env.drift})')\n",
    "plt.title(rf'Mean of P&L ($\\mu$={0.0})')\n",
    "plt.plot(xrange, list(map(np.mean, rl_pnls_vol)), 'o-', label='DDPG')\n",
    "plt.plot(xrange, list(map(np.mean, ntb_pnls_vol)), 'o-', label='NTB')\n",
    "# plt.xlabel('volatility')\n",
    "plt.xlabel('volatility')\n",
    "plt.xticks(xrange)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xrange = np.arange(0.2, 1.2, 0.2)\n",
    "\n",
    "plt.title(rf'CVaR(95%) of P&L ($\\mu$={0.0})')\n",
    "plt.plot(xrange, list(map(cvar, rl_pnls_vol)), 'o-', label='DDPG')\n",
    "plt.plot(xrange, list(map(cvar, ntb_pnls_vol)), 'o-', label='NTB')\n",
    "plt.xlabel('volatility')\n",
    "# plt.xlabel('drift')\n",
    "plt.xticks(xrange)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from Algorithms.ddpg import config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Plot Setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib\n",
    "\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "FONTSIZE = 10\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 100\n",
    "matplotlib.rcParams[\"figure.titlesize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"legend.fontsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"xtick.labelsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"ytick.labelsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"axes.labelsize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"axes.titlesize\"] = FONTSIZE\n",
    "matplotlib.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "matplotlib.rcParams[\"savefig.pad_inches\"] = 0.1\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2\n",
    "matplotlib.rcParams[\"axes.linewidth\"] = 1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Model Setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Load Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env 'BSMarket was created!\n",
      "env 'BSMarket was created!\n"
     ]
    }
   ],
   "source": [
    "env_kwargs, model_kwargs, learn_kwargs = config.load_config('tmp_config.yaml')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ntb_mode = True\n",
    "double_ddpg = True\n",
    "\n",
    "env_kwargs.update({\n",
    "    'reward_fn': 'mean var',\n",
    "    'reward_fn_kwargs': {},\n",
    "    'reward_mode': 'pnl'\n",
    "})\n",
    "\n",
    "model_kwargs.update({\n",
    "    'buffer_size': 300,\n",
    "    'learning_starts': 300,\n",
    "    'batch_size': 15,\n",
    "    'std_coeff': 0.05\n",
    "})\n",
    "\n",
    "model_kwargs['policy_kwargs'].update({\n",
    "    'ntb_mode': ntb_mode,\n",
    "    'double_ddpg': double_ddpg,\n",
    "})\n",
    "\n",
    "learn_kwargs.update({\n",
    "    'total_timesteps': 1500\n",
    "})\n",
    "\n",
    "# del model_kwargs['std_coeff']\n",
    "\n",
    "if ntb_mode:\n",
    "    actor_net_kwargs = {'bn_kwargs': {'num_features': env_kwargs['n_assets']}}\n",
    "    critic_net_kwargs = {'bn_kwargs': {'num_features': env_kwargs['n_assets']}}\n",
    "\n",
    "\n",
    "    model_kwargs['policy_kwargs'].update({\n",
    "        'net_arch': {'pi': [(nn.BatchNorm1d, 'bn'), 32, 32],\n",
    "                     'qf': [(nn.BatchNorm1d, 'bn'), 2]},\n",
    "        'actor_net_kwargs': actor_net_kwargs,\n",
    "        'critic_net_kwargs': critic_net_kwargs,\n",
    "    })\n",
    "\n",
    "    model_kwargs['policy_kwargs']['features_extractor_kwargs'].update({\n",
    "        'features_out': 64,\n",
    "        'net_arch': [32]\n",
    "    })\n",
    "\n",
    "else:\n",
    "    model_kwargs['policy_kwargs'].update({\n",
    "        'net_arch': [],\n",
    "    })\n",
    "\n",
    "    model_kwargs['policy_kwargs']['features_extractor_kwargs'].update({\n",
    "        'features_out': 2,\n",
    "        'net_arch': [32, 64]\n",
    "    })\n",
    "\n",
    "model_kwargs['policy_kwargs']['one_asset'] = (env_kwargs['n_assets']==1)\n",
    "\n",
    "# model_kwargs['policy_kwargs']['features_extractor_kwargs'].update({\n",
    "#     'features_in': 5\n",
    "# })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env 'BSMarket was created!\n",
      "model_kwargs['env']: <BSMarket instance>\n",
      "env 'BSMarket was created!\n",
      "learn_kwargs['eval_env']: <BSMarketEval instance>\n",
      "learn_kwargs['tb_log_name']: ddpg_220615-2134\n",
      "learn_kwargs['eval_log_path']: ../logs/tb_logs/ddpg_220615-2134_1\n"
     ]
    }
   ],
   "source": [
    "config.reconstruct_config(env_kwargs, model_kwargs, learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cost': 0.02,\n",
      " 'dividend': 0.0,\n",
      " 'drift': 0.0,\n",
      " 'freq': 1,\n",
      " 'gen_name': 'gbm',\n",
      " 'init_price': 1.0,\n",
      " 'maturity': 30,\n",
      " 'n_assets': 1000,\n",
      " 'payoff': 'european',\n",
      " 'payoff_coeff': 1.0,\n",
      " 'period_unit': 365,\n",
      " 'reward_fn': 'mean var',\n",
      " 'reward_fn_kwargs': {},\n",
      " 'reward_mode': 'pnl',\n",
      " 'risk_free_interest': 0.0,\n",
      " 'strike': 1.0,\n",
      " 'volatility': 0.2}\n"
     ]
    }
   ],
   "source": [
    "pprint(env_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_noise': NormalActionNoise(mu=0.0, sigma=0.1),\n",
      " 'batch_size': 15,\n",
      " 'buffer_size': 300,\n",
      " 'create_eval_env': False,\n",
      " 'device': 'auto',\n",
      " 'env': <Env.env.BSMarket object at 0x000002284FB5C1F0>,\n",
      " 'gamma': 0.99,\n",
      " 'gradient_steps': -1,\n",
      " 'learning_rate': <function lr_schedule at 0x000002284F984B80>,\n",
      " 'learning_starts': 300,\n",
      " 'optimize_memory_usage': False,\n",
      " 'policy': <class 'Algorithms.ddpg.policies.DoubleDDPGPolicy'>,\n",
      " 'policy_kwargs': {'activation_fn': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "                   'actor_net_kwargs': {'bn_kwargs': {'num_features': 1000}},\n",
      "                   'critic_net_kwargs': {'bn_kwargs': {'num_features': 1000}},\n",
      "                   'double_ddpg': True,\n",
      "                   'features_extractor_class': <class 'Env.feature_extractor.MarketObsExtractor'>,\n",
      "                   'features_extractor_kwargs': {'activation_fn': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "                                                 'features_in': 4,\n",
      "                                                 'features_out': 64,\n",
      "                                                 'last_activation_fn': <class 'torch.nn.modules.activation.ReLU'>,\n",
      "                                                 'net_arch': [32]},\n",
      "                   'n_critics': 1,\n",
      "                   'net_arch': {'pi': [(<class 'torch.nn.modules.batchnorm.BatchNorm1d'>,\n",
      "                                        'bn'),\n",
      "                                       32,\n",
      "                                       32],\n",
      "                                'qf': [(<class 'torch.nn.modules.batchnorm.BatchNorm1d'>,\n",
      "                                        'bn'),\n",
      "                                       2]},\n",
      "                   'normalize_images': False,\n",
      "                   'ntb_mode': True,\n",
      "                   'one_asset': False,\n",
      "                   'optimizer_class': <class 'torch.optim.adam.Adam'>,\n",
      "                   'optimizer_kwargs': None,\n",
      "                   'share_features_extractor': True},\n",
      " 'replay_buffer_class': <class 'Env.buffers.CustomReplayBuffer'>,\n",
      " 'replay_buffer_kwargs': {},\n",
      " 'seed': 42,\n",
      " 'std_coeff': 0.05,\n",
      " 'tau': 0.005,\n",
      " 'tensorboard_log': '../logs/tb_logs',\n",
      " 'train_freq': (1, 'episode'),\n",
      " 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'callback': <Algorithms.ddpg.callbacks.ReportCallbacks object at 0x000002284FAE6FD0>,\n",
      " 'eval_env': <Env.env.BSMarketEval object at 0x0000022818FF2A30>,\n",
      " 'eval_freq': 30,\n",
      " 'eval_log_path': '../logs/tb_logs/ddpg_220615-2134_1',\n",
      " 'log_interval': 30,\n",
      " 'n_eval_episodes': 1,\n",
      " 'reset_num_timesteps': True,\n",
      " 'tb_log_name': 'ddpg_220615-2134',\n",
      " 'total_timesteps': 1500}\n"
     ]
    }
   ],
   "source": [
    "pprint(learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Make env, model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.ddpg import DoubleDDPG\n",
    "from stable_baselines3.ddpg import DDPG\n",
    "# from Algorithms.ddpg.double_ddpg import DDPG\n",
    "\n",
    "# model = DoubleDDPG(**model_kwargs)\n",
    "model = DoubleDDPG(**model_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "DoubleDDPGPolicy(\n  (actor): CustomActor(\n    (features_extractor): MarketObsExtractor(\n      (layers): Sequential(\n        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Linear(in_features=4, out_features=32, bias=True)\n        (2): ReLU()\n        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Linear(in_features=32, out_features=64, bias=True)\n        (5): ReLU()\n      )\n    )\n    (mu): Sequential(\n      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=64, out_features=32, bias=True)\n      (2): ReLU()\n      (3): Linear(in_features=32, out_features=32, bias=True)\n      (4): ReLU()\n      (5): Linear(in_features=32, out_features=2, bias=True)\n      (6): Tanh()\n    )\n    (flatten): Flatten(start_dim=-2, end_dim=-1)\n  )\n  (actor_target): CustomActor(\n    (features_extractor): MarketObsExtractor(\n      (layers): Sequential(\n        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Linear(in_features=4, out_features=32, bias=True)\n        (2): ReLU()\n        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Linear(in_features=32, out_features=64, bias=True)\n        (5): ReLU()\n      )\n    )\n    (mu): Sequential(\n      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=64, out_features=32, bias=True)\n      (2): ReLU()\n      (3): Linear(in_features=32, out_features=32, bias=True)\n      (4): ReLU()\n      (5): Linear(in_features=32, out_features=2, bias=True)\n      (6): Tanh()\n    )\n    (flatten): Flatten(start_dim=-2, end_dim=-1)\n  )\n  (critic): CustomContinuousCritic(\n    (features_extractor): MarketObsExtractor(\n      (layers): Sequential(\n        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Linear(in_features=4, out_features=32, bias=True)\n        (2): ReLU()\n        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Linear(in_features=32, out_features=64, bias=True)\n        (5): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=65, out_features=2, bias=True)\n      (2): ReLU()\n      (3): Linear(in_features=2, out_features=1, bias=True)\n    )\n  )\n  (critic_target): CustomContinuousCritic(\n    (features_extractor): MarketObsExtractor(\n      (layers): Sequential(\n        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Linear(in_features=4, out_features=32, bias=True)\n        (2): ReLU()\n        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Linear(in_features=32, out_features=64, bias=True)\n        (5): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=65, out_features=2, bias=True)\n      (2): ReLU()\n      (3): Linear(in_features=2, out_features=1, bias=True)\n    )\n  )\n  (critic2): CustomContinuousCritic(\n    (features_extractor): MarketObsExtractor(\n      (layers): Sequential(\n        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Linear(in_features=4, out_features=32, bias=True)\n        (2): ReLU()\n        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Linear(in_features=32, out_features=64, bias=True)\n        (5): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=65, out_features=2, bias=True)\n      (2): ReLU()\n      (3): Linear(in_features=2, out_features=1, bias=True)\n    )\n  )\n  (critic2_target): CustomContinuousCritic(\n    (features_extractor): MarketObsExtractor(\n      (layers): Sequential(\n        (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Linear(in_features=4, out_features=32, bias=True)\n        (2): ReLU()\n        (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Linear(in_features=32, out_features=64, bias=True)\n        (5): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=65, out_features=2, bias=True)\n      (2): ReLU()\n      (3): Linear(in_features=2, out_features=1, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ../logs/tb_logs\\ddpg_220615-2134_1\n",
      "[Training Start]\n",
      "Eval num_timesteps=30, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0155  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 30       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=60, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0162  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 60       |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0139  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 90       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=120, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0153  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 120      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=150, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0148  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 150      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0157  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 180      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=210, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0156  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 210      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0143  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 240      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=270, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0153  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 270      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0144  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 300      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=330, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0152  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 330      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=360, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0226  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 360      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.339    |\n",
      "|    critic2_loss    | 0.0104   |\n",
      "|    critic_loss     | 0.0104   |\n",
      "|    learning_rate   | 0.00203  |\n",
      "|    mean_cost_loss  | -0.315   |\n",
      "|    n_updates       | 30       |\n",
      "|    std_cost_loss   | 0.0235   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=390, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0231  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 390      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.329    |\n",
      "|    critic2_loss    | 0.000775 |\n",
      "|    critic_loss     | 0.00267  |\n",
      "|    learning_rate   | 0.00189  |\n",
      "|    mean_cost_loss  | -0.306   |\n",
      "|    n_updates       | 60       |\n",
      "|    std_cost_loss   | 0.0228   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=420, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0239  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 420      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.336    |\n",
      "|    critic2_loss    | 0.000552 |\n",
      "|    critic_loss     | 0.00296  |\n",
      "|    learning_rate   | 0.00176  |\n",
      "|    mean_cost_loss  | -0.313   |\n",
      "|    n_updates       | 90       |\n",
      "|    std_cost_loss   | 0.0227   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=450, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0227  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 450      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.33     |\n",
      "|    critic2_loss    | 0.000361 |\n",
      "|    critic_loss     | 0.00248  |\n",
      "|    learning_rate   | 0.00165  |\n",
      "|    mean_cost_loss  | -0.308   |\n",
      "|    n_updates       | 120      |\n",
      "|    std_cost_loss   | 0.0226   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=480, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0209  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 480      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.323    |\n",
      "|    critic2_loss    | 0.000443 |\n",
      "|    critic_loss     | 0.00311  |\n",
      "|    learning_rate   | 0.00155  |\n",
      "|    mean_cost_loss  | -0.301   |\n",
      "|    n_updates       | 150      |\n",
      "|    std_cost_loss   | 0.0222   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=510, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 510      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.32     |\n",
      "|    critic2_loss    | 0.000242 |\n",
      "|    critic_loss     | 0.00181  |\n",
      "|    learning_rate   | 0.00145  |\n",
      "|    mean_cost_loss  | -0.298   |\n",
      "|    n_updates       | 180      |\n",
      "|    std_cost_loss   | 0.022    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=540, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0222  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 540      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.32     |\n",
      "|    critic2_loss    | 0.000233 |\n",
      "|    critic_loss     | 0.00178  |\n",
      "|    learning_rate   | 0.00136  |\n",
      "|    mean_cost_loss  | -0.298   |\n",
      "|    n_updates       | 210      |\n",
      "|    std_cost_loss   | 0.0219   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=570, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0225  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 570      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.318    |\n",
      "|    critic2_loss    | 0.000316 |\n",
      "|    critic_loss     | 0.00244  |\n",
      "|    learning_rate   | 0.00128  |\n",
      "|    mean_cost_loss  | -0.296   |\n",
      "|    n_updates       | 240      |\n",
      "|    std_cost_loss   | 0.0217   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=600, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0229  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 600      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.313    |\n",
      "|    critic2_loss    | 0.000332 |\n",
      "|    critic_loss     | 0.00258  |\n",
      "|    learning_rate   | 0.00121  |\n",
      "|    mean_cost_loss  | -0.292   |\n",
      "|    n_updates       | 270      |\n",
      "|    std_cost_loss   | 0.0214   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=630, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0235  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 630      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.31     |\n",
      "|    critic2_loss    | 0.00039  |\n",
      "|    critic_loss     | 0.00301  |\n",
      "|    learning_rate   | 0.00115  |\n",
      "|    mean_cost_loss  | -0.289   |\n",
      "|    n_updates       | 300      |\n",
      "|    std_cost_loss   | 0.0213   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=660, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0231  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 660      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.31     |\n",
      "|    critic2_loss    | 0.000197 |\n",
      "|    critic_loss     | 0.00152  |\n",
      "|    learning_rate   | 0.00108  |\n",
      "|    mean_cost_loss  | -0.289   |\n",
      "|    n_updates       | 330      |\n",
      "|    std_cost_loss   | 0.0213   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=690, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0229  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 690      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.31     |\n",
      "|    critic2_loss    | 0.000279 |\n",
      "|    critic_loss     | 0.00215  |\n",
      "|    learning_rate   | 0.00103  |\n",
      "|    mean_cost_loss  | -0.288   |\n",
      "|    n_updates       | 360      |\n",
      "|    std_cost_loss   | 0.0212   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=720, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0215  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.308    |\n",
      "|    critic2_loss    | 0.000359 |\n",
      "|    critic_loss     | 0.00277  |\n",
      "|    learning_rate   | 0.000979 |\n",
      "|    mean_cost_loss  | -0.287   |\n",
      "|    n_updates       | 390      |\n",
      "|    std_cost_loss   | 0.0211   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=750, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0243  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 750      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.305    |\n",
      "|    critic2_loss    | 0.000232 |\n",
      "|    critic_loss     | 0.00179  |\n",
      "|    learning_rate   | 0.000932 |\n",
      "|    mean_cost_loss  | -0.284   |\n",
      "|    n_updates       | 420      |\n",
      "|    std_cost_loss   | 0.021    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=780, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0216  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 780      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.305    |\n",
      "|    critic2_loss    | 0.000249 |\n",
      "|    critic_loss     | 0.00193  |\n",
      "|    learning_rate   | 0.000889 |\n",
      "|    mean_cost_loss  | -0.284   |\n",
      "|    n_updates       | 450      |\n",
      "|    std_cost_loss   | 0.021    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=810, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0221  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 810      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.304    |\n",
      "|    critic2_loss    | 0.000347 |\n",
      "|    critic_loss     | 0.00269  |\n",
      "|    learning_rate   | 0.00085  |\n",
      "|    mean_cost_loss  | -0.283   |\n",
      "|    n_updates       | 480      |\n",
      "|    std_cost_loss   | 0.0209   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=840, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0219  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 840      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.301    |\n",
      "|    critic2_loss    | 0.000205 |\n",
      "|    critic_loss     | 0.0016   |\n",
      "|    learning_rate   | 0.000814 |\n",
      "|    mean_cost_loss  | -0.281   |\n",
      "|    n_updates       | 510      |\n",
      "|    std_cost_loss   | 0.0208   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=870, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0221  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 870      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.301    |\n",
      "|    critic2_loss    | 0.000262 |\n",
      "|    critic_loss     | 0.00204  |\n",
      "|    learning_rate   | 0.000781 |\n",
      "|    mean_cost_loss  | -0.28    |\n",
      "|    n_updates       | 540      |\n",
      "|    std_cost_loss   | 0.0208   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=900, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0231  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 900      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.301    |\n",
      "|    critic2_loss    | 0.00022  |\n",
      "|    critic_loss     | 0.00172  |\n",
      "|    learning_rate   | 0.000751 |\n",
      "|    mean_cost_loss  | -0.28    |\n",
      "|    n_updates       | 570      |\n",
      "|    std_cost_loss   | 0.0208   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.109   |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 25       |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total timesteps | 900      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=930, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0218  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 930      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.299    |\n",
      "|    critic2_loss    | 0.00041  |\n",
      "|    critic_loss     | 0.00321  |\n",
      "|    learning_rate   | 0.000723 |\n",
      "|    mean_cost_loss  | -0.278   |\n",
      "|    n_updates       | 600      |\n",
      "|    std_cost_loss   | 0.0206   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=960, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0226  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 960      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.294    |\n",
      "|    critic2_loss    | 0.000327 |\n",
      "|    critic_loss     | 0.00256  |\n",
      "|    learning_rate   | 0.000697 |\n",
      "|    mean_cost_loss  | -0.274   |\n",
      "|    n_updates       | 630      |\n",
      "|    std_cost_loss   | 0.0204   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=990, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0227  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 990      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.293    |\n",
      "|    critic2_loss    | 0.000305 |\n",
      "|    critic_loss     | 0.00239  |\n",
      "|    learning_rate   | 0.000674 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 660      |\n",
      "|    std_cost_loss   | 0.0203   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1020, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0228  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1020     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.292    |\n",
      "|    critic2_loss    | 0.000283 |\n",
      "|    critic_loss     | 0.00222  |\n",
      "|    learning_rate   | 0.000652 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 690      |\n",
      "|    std_cost_loss   | 0.0203   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1050, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0221  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1050     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.292    |\n",
      "|    critic2_loss    | 0.000298 |\n",
      "|    critic_loss     | 0.00233  |\n",
      "|    learning_rate   | 0.000633 |\n",
      "|    mean_cost_loss  | -0.272   |\n",
      "|    n_updates       | 720      |\n",
      "|    std_cost_loss   | 0.0203   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1080, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0226  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1080     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.289    |\n",
      "|    critic2_loss    | 0.000348 |\n",
      "|    critic_loss     | 0.00273  |\n",
      "|    learning_rate   | 0.000615 |\n",
      "|    mean_cost_loss  | -0.269   |\n",
      "|    n_updates       | 750      |\n",
      "|    std_cost_loss   | 0.0201   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1110, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0233  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1110     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.287    |\n",
      "|    critic2_loss    | 0.00022  |\n",
      "|    critic_loss     | 0.00174  |\n",
      "|    learning_rate   | 0.000599 |\n",
      "|    mean_cost_loss  | -0.267   |\n",
      "|    n_updates       | 780      |\n",
      "|    std_cost_loss   | 0.02     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1140, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0212  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1140     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.288    |\n",
      "|    critic2_loss    | 0.00027  |\n",
      "|    critic_loss     | 0.00213  |\n",
      "|    learning_rate   | 0.000584 |\n",
      "|    mean_cost_loss  | -0.268   |\n",
      "|    n_updates       | 810      |\n",
      "|    std_cost_loss   | 0.0201   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1170, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0222  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1170     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.286    |\n",
      "|    critic2_loss    | 0.00025  |\n",
      "|    critic_loss     | 0.00197  |\n",
      "|    learning_rate   | 0.000571 |\n",
      "|    mean_cost_loss  | -0.266   |\n",
      "|    n_updates       | 840      |\n",
      "|    std_cost_loss   | 0.0199   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1200, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0237  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.286    |\n",
      "|    critic2_loss    | 0.000195 |\n",
      "|    critic_loss     | 0.00155  |\n",
      "|    learning_rate   | 0.000559 |\n",
      "|    mean_cost_loss  | -0.266   |\n",
      "|    n_updates       | 870      |\n",
      "|    std_cost_loss   | 0.02     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1230, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0228  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1230     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.284    |\n",
      "|    critic2_loss    | 0.000364 |\n",
      "|    critic_loss     | 0.00288  |\n",
      "|    learning_rate   | 0.000548 |\n",
      "|    mean_cost_loss  | -0.264   |\n",
      "|    n_updates       | 900      |\n",
      "|    std_cost_loss   | 0.0198   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1260, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0231  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1260     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.282    |\n",
      "|    critic2_loss    | 0.000124 |\n",
      "|    critic_loss     | 0.000986 |\n",
      "|    learning_rate   | 0.000539 |\n",
      "|    mean_cost_loss  | -0.263   |\n",
      "|    n_updates       | 930      |\n",
      "|    std_cost_loss   | 0.0197   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1290, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0228  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1290     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.283    |\n",
      "|    critic2_loss    | 0.000172 |\n",
      "|    critic_loss     | 0.00137  |\n",
      "|    learning_rate   | 0.00053  |\n",
      "|    mean_cost_loss  | -0.263   |\n",
      "|    n_updates       | 960      |\n",
      "|    std_cost_loss   | 0.0198   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1320, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0235  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1320     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.281    |\n",
      "|    critic2_loss    | 0.000305 |\n",
      "|    critic_loss     | 0.00244  |\n",
      "|    learning_rate   | 0.000523 |\n",
      "|    mean_cost_loss  | -0.262   |\n",
      "|    n_updates       | 990      |\n",
      "|    std_cost_loss   | 0.0197   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1350, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0235  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1350     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.278    |\n",
      "|    critic2_loss    | 0.000347 |\n",
      "|    critic_loss     | 0.00277  |\n",
      "|    learning_rate   | 0.000517 |\n",
      "|    mean_cost_loss  | -0.259   |\n",
      "|    n_updates       | 1020     |\n",
      "|    std_cost_loss   | 0.0195   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1380, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.022   |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1380     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.276    |\n",
      "|    critic2_loss    | 0.000199 |\n",
      "|    critic_loss     | 0.0016   |\n",
      "|    learning_rate   | 0.000512 |\n",
      "|    mean_cost_loss  | -0.257   |\n",
      "|    n_updates       | 1050     |\n",
      "|    std_cost_loss   | 0.0194   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1410, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0221  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1410     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.277    |\n",
      "|    critic2_loss    | 0.000229 |\n",
      "|    critic_loss     | 0.00183  |\n",
      "|    learning_rate   | 0.000507 |\n",
      "|    mean_cost_loss  | -0.257   |\n",
      "|    n_updates       | 1080     |\n",
      "|    std_cost_loss   | 0.0194   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1440, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0224  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1440     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.276    |\n",
      "|    critic2_loss    | 0.000242 |\n",
      "|    critic_loss     | 0.00194  |\n",
      "|    learning_rate   | 0.000504 |\n",
      "|    mean_cost_loss  | -0.256   |\n",
      "|    n_updates       | 1110     |\n",
      "|    std_cost_loss   | 0.0194   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1470, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0229  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1470     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.273    |\n",
      "|    critic2_loss    | 0.0003   |\n",
      "|    critic_loss     | 0.00241  |\n",
      "|    learning_rate   | 0.000502 |\n",
      "|    mean_cost_loss  | -0.254   |\n",
      "|    n_updates       | 1140     |\n",
      "|    std_cost_loss   | 0.0192   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1500, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.0233  |\n",
      "| time/              |          |\n",
      "|    total timesteps | 1500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.269    |\n",
      "|    critic2_loss    | 0.000371 |\n",
      "|    critic_loss     | 0.00298  |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    mean_cost_loss  | -0.25    |\n",
      "|    n_updates       | 1170     |\n",
      "|    std_cost_loss   | 0.019    |\n",
      "---------------------------------\n",
      "[Training End]  steps: 1500\ttimes: 66.69044804573059\n"
     ]
    }
   ],
   "source": [
    "model = model.learn(**learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BSMarket instance> will be save as name. env_kwargs not in kwargs!\n",
      "<BSMarketEval instance> will be save as name. eval_env_kwargs not in kwargs!\n",
      "<Algorithms.ddpg.callbacks.ReportCallbacks object at 0x000002284FAE6FD0> will be save as name. callback_kwargs not in kwargs!\n",
      "../logs/tb_logs/ddpg_220615-2134_1/config.yaml was saved.\n"
     ]
    }
   ],
   "source": [
    "config.save_config(f'{learn_kwargs[\"eval_log_path\"]}/config.yaml', env_kwargs, model_kwargs, learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. P&L Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logs/tb_logs/ddpg_220615-2134_1/best_model\n"
     ]
    }
   ],
   "source": [
    "# model = model.load('../logs/tb_logs/ddpg_220607-2214_stable'+'/best_model')\n",
    "# model = model.load('../logs/tb_logs/ddpg_220607-2124_ntb_delta'+'/best_model')\n",
    "# model = model.load('../logs/tb_logs/ddpg_220608-2037_1'+'/best_model')\n",
    "# model = model.load('../logs/tb_logs/ddpg_220614-2216_1_ntb_pnl'+'/best_model')\n",
    "# model = model.load('../logs/tb_logs/ddpg_220614-2213_1_ddpg_pnl'+'/best_model')\n",
    "model = model.load(learn_kwargs['eval_log_path'] + '/best_model')\n",
    "print(learn_kwargs['eval_log_path'] + '/best_model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "eval_env = learn_kwargs['eval_env']\n",
    "eval_env.reward_mode = 'pnl'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# random_pnl = np.mean([eval_env.pnl_eval() for _ in range(30)], axis=0)\n",
    "# delta_pnl = np.mean([eval_env.delta_eval() for _ in range(30)], axis=0)\n",
    "# rl_pnl = np.mean([eval_env.pnl_eval(model) for _ in range(30)], axis=0)\n",
    "\n",
    "# random_pnl = np.load('best_results/random_pnl.npy')\n",
    "# delta_pnl = np.load('best_results/ntb_pnl.npy')\n",
    "rl_pnl = np.load('best_results/rl_pnl_0614.npy')\n",
    "# rl_pnl = np.load('best_results/rl_pnl_eval_cash.npy')\n",
    "# ntb_pnl = np.load('best_results/ntb_pnl_eval_cash.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# np.save('best_results/rl_pnl_0614', ntb_pnl)\n",
    "# np.save('best_results/delta_pnl', delta_pnl)\n",
    "# np.save('best_results/rl_pnl', rl_pnl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "ntb_pnl = np.mean([eval_env.pnl_eval(model) for _ in range(30)], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pnl_reward(pnl):\n",
    "    mean = np.mean(pnl)\n",
    "    std = np.std(pnl)\n",
    "    return mean - 0.02 * std , (mean, std)\n",
    "\n",
    "def sharpe_ratio(pnl):\n",
    "    return pnl.mean()/pnl.std()\n",
    "\n",
    "def var(pnl, ratio):\n",
    "    losses = np.sort(-pnl)\n",
    "    boundary = int(np.ceil(losses.shape[-1]*ratio))\n",
    "    return losses[boundary]\n",
    "\n",
    "def cvar(pnl, ratio=0.95):\n",
    "    losses = np.sort(-pnl)\n",
    "    boundary = int(np.ceil(losses.shape[-1]*ratio))\n",
    "    return np.mean(losses[boundary:], axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntb pnl:\t\t-0.0386, -0.0385, 0.0029\n",
      "rl pnl:\t\t-0.0000, 0.0001, 0.0061\n",
      "ntb sharpe:\t\t-13.05847\n",
      "rl sharpe:\t\t0.01507\n",
      "ntb cvar:\t\t0.04529\n",
      "rl cvar:\t\t0.01384\n"
     ]
    }
   ],
   "source": [
    "plt_kwargs = {'bins': 100,\n",
    "              # 'range': (-0.04, 0.01),\n",
    "              'alpha': 0.6}\n",
    "\n",
    "plt.xlabel('P&L')\n",
    "# plt.hist(random_pnl, bins=100, range=(-0.25, 0.05), alpha=0.6, label='random')\n",
    "# plt.hist(random_pnl, bins=100, range=(-0.1, 0.05), alpha=0.6, label='random')\n",
    "# plt.hist(delta_pnl, **plt_kwargs, label='delta')\n",
    "plt.hist(ntb_pnl,**plt_kwargs, label='DDPG+NTB')\n",
    "plt.hist(rl_pnl, **plt_kwargs, label='DDPG')\n",
    "# plt.ylim(0, 150)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# r1, (m1, s1) = pnl_reward(random_pnl)\n",
    "r2, (m2, s2) = pnl_reward(ntb_pnl)\n",
    "r3, (m3, s3) = pnl_reward(rl_pnl)\n",
    "# print(f'random:\\t{r1:.4f}, {m1:.4f}, {s1:.4f}')\n",
    "print(f'ntb pnl:\\t\\t{r2:.4f}, {m2:.4f}, {s2:.4f}')\n",
    "print(f'rl pnl:\\t\\t{r3:.4f}, {m3:.4f}, {s3:.4f}')\n",
    "# print((r2-r1))\n",
    "# print((r3-r2))\n",
    "\n",
    "print(f'ntb sharpe:\\t\\t{sharpe_ratio(ntb_pnl):.5f}')\n",
    "print(f'rl sharpe:\\t\\t{sharpe_ratio(rl_pnl):.5f}')\n",
    "\n",
    "print(f'ntb cvar:\\t\\t{cvar(ntb_pnl):.5f}')\n",
    "print(f'rl cvar:\\t\\t{cvar(rl_pnl):.5f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.022955209587592933, 0.00333743451844443)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntb_pnl.mean(), ntb_pnl.std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.022750967764943068, 0.006194732383409264)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_pnl.mean(), rl_pnl.std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "np.save('best_results/ntb_pnl_0614', ntb_pnl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "np.save('best_results/rl_pnl_eval_cash', rl_pnl,)\n",
    "np.save('best_results/ntb_pnl_eval_cash', ntb_pnl,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.023253765816845084\n",
      "-0.02307192182905543\n"
     ]
    }
   ],
   "source": [
    "from Utils.prices import pnl_entropic_loss\n",
    "\n",
    "def loss(pnl, aversion=0.0):\n",
    "    return np.mean((1-np.exp(-aversion * pnl))/(aversion+1e-7))\n",
    "\n",
    "print(loss(ntb_pnl, aversion=1.1))\n",
    "print(loss(rl_pnl, aversion=1.1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02867360759284007 0.03344846486958373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ntb_loss = pd.Series(-ntb_pnl)\n",
    "rl_loss = pd.Series(-rl_pnl)\n",
    "\n",
    "var95_ntb = ntb_loss.quantile(0.95)\n",
    "var95_rl = rl_loss.quantile(0.95)\n",
    "\n",
    "print(var95_ntb, var95_rl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030563063997726295\n"
     ]
    }
   ],
   "source": [
    "print(ntb_loss[ntb_loss >= var95_ntb].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03678241960186988\n"
     ]
    }
   ],
   "source": [
    "print(rl_loss[rl_loss >= var95_rl].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030563063997726295 0.03678241960186988\n"
     ]
    }
   ],
   "source": [
    "print(cvar(ntb_pnl, 0.95), cvar(rl_pnl, 0.95))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.randn(3,4).shape[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "rl_pnl = ntb_pnl.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## New Problem\n",
    "\n",
    "총 얼마 썼는가?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cash_eval(env, model=None):\n",
    "    obs = env.reset()\n",
    "    done, info = False, {}\n",
    "    cash = 0\n",
    "    while not done:\n",
    "        if model:\n",
    "            action, _ = model.predict(obs, deterministic=False)\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        obs, reward, done, info = env.cashflow_pnl(action)\n",
    "        cash += info['raw_reward']\n",
    "        print(np.mean(info['raw_reward']))\n",
    "\n",
    "    return cash"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "ntb_cash = np.load('best_results/ntb_cash_0614.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "rl_cash = np.mean([cash_eval(eval_env, model) for _ in range(30)], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntb_pnl:\t-0.0152, -0.0151, 0.0030\n",
      "rl:\t\t-0.0230, -0.0229, 0.0057\n"
     ]
    }
   ],
   "source": [
    "plt_kwargs = {'bins': 100,\n",
    "              'range': (-0.04, -0.01),\n",
    "              'alpha': 0.6}\n",
    "\n",
    "plt.xlabel('P&L')\n",
    "plt.hist(ntb_cash,**plt_kwargs, label='ntb')\n",
    "plt.hist(rl_cash, **plt_kwargs, label='rl')\n",
    "# plt.ylim(0, 150)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# r1, (m1, s1) = pnl_reward(random_pnl)\n",
    "r2, (m2, s2) = pnl_reward(ntb_cash)\n",
    "r3, (m3, s3) = pnl_reward(rl_cash)\n",
    "# print(f'random:\\t{r1:.4f}, {m1:.4f}, {s1:.4f}')\n",
    "print(f'ntb_pnl:\\t{r2:.4f}, {m2:.4f}, {s2:.4f}')\n",
    "print(f'rl:\\t\\t{r3:.4f}, {m3:.4f}, {s3:.4f}')\n",
    "# print((r2-r1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "np.save('best_results/ntb_cash_0614', ntb_cash)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from run import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    obs = env.reset()\n",
    "    reward, done, info = 0, False, {}\n",
    "    total_reward = reward\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        action = model.policy.unscale_action(action)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f'Result: {reward}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: -0.03249866840861704\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = default_config()\n",
    "env_kwargs = config['env_kwargs']\n",
    "model_kwargs = config['model_kwargs']\n",
    "learn_kwargs = config['learn_kwargs']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_assets': 1000,\n 'cost': 0.02,\n 'n_periods': 30,\n 'freq': 1,\n 'period_unit': 365,\n 'drift': 0.0,\n 'volatility': 0.2,\n 'init_price': 1.0,\n 'risk_free_interest': 0.0,\n 'strike': 1.0,\n 'dividend': 0.0,\n 'payoff': 'european',\n 'gen_name': 'gbm',\n 'reward_mode': 'pnl'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'total_timesteps': 500,\n 'callback': <Algorithms.learn.callbacks.ReportCallbacks at 0x2514c6a2040>,\n 'log_interval': 30,\n 'eval_env': <Env.env.BSMarket at 0x251154100a0>,\n 'eval_freq': 30,\n 'n_eval_episodes': 1,\n 'tb_log_name': 'ddpg_220522-0019',\n 'eval_log_path': 'logs/tb_logs/ddpg_220522-0019_1',\n 'reset_num_timesteps': True}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'policy': Algorithms.policies.DoubleTD3Policy,\n 'env': <Env.env.BSMarket at 0x2514c691b80>,\n 'learning_rate': <function run.lr_schedule(left: float)>,\n 'buffer_size': 100,\n 'learning_starts': 100,\n 'batch_size': 10,\n 'tau': 0.005,\n 'gamma': 0.99,\n 'train_freq': (1, 'episode'),\n 'gradient_steps': 5,\n 'action_noise': NormalActionNoise(mu=0.0, sigma=0.1),\n 'replay_buffer_class': None,\n 'replay_buffer_kwargs': None,\n 'optimize_memory_usage': False,\n 'tensorboard_log': 'logs/tb_logs',\n 'create_eval_env': False,\n 'policy_kwargs': {'net_arch': [],\n  'activation_fn': torch.nn.modules.activation.ReLU,\n  'features_extractor_class': Env.feature_extractor.BatchNormExtractor,\n  'features_extractor_kwargs': {'features_in': 4,\n   'features_out': 2,\n   'net_arch': [32, 64],\n   'activation_fn': torch.nn.modules.activation.ReLU},\n  'normalize_images': False,\n  'optimizer_class': torch.optim.adam.Adam,\n  'optimizer_kwargs': None,\n  'n_critics': 1,\n  'share_features_extractor': True},\n 'verbose': 1,\n 'seed': 42,\n 'device': 'auto'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_config.yaml was saved.\n"
     ]
    }
   ],
   "source": [
    "save_config('tmp_config.yaml', env_kwargs, model_kwargs, learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "env_kwargs, model_kwargs, learn_kwargs = load_config('tmp_config.yaml')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cost': 0.02,\n 'dividend': 0.0,\n 'drift': 0.0,\n 'freq': 1,\n 'gen_name': 'gbm',\n 'init_price': 1.0,\n 'n_assets': 1000,\n 'n_periods': 30,\n 'payoff': 'european',\n 'period_unit': 365,\n 'reward_mode': 'pnl',\n 'risk_free_interest': 0.0,\n 'strike': 1.0,\n 'volatility': 0.2}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'action_noise': NormalActionNoise(mu=0.0, sigma=0.1),\n 'batch_size': 10,\n 'buffer_size': 100,\n 'create_eval_env': False,\n 'device': 'auto',\n 'env': <Env.env.BSMarket at 0x272c57c2100>,\n 'gamma': 0.99,\n 'gradient_steps': 5,\n 'learning_rate': <function run.lr_schedule(left: float)>,\n 'learning_starts': 100,\n 'optimize_memory_usage': False,\n 'policy': Algorithms.policies.DoubleTD3Policy,\n 'policy_kwargs': {'activation_fn': torch.nn.modules.activation.ReLU,\n  'features_extractor_class': Env.feature_extractor.BatchNormExtractor,\n  'features_extractor_kwargs': {'activation_fn': torch.nn.modules.activation.ReLU,\n   'features_in': 4,\n   'features_out': 2,\n   'net_arch': [32, 64]},\n  'n_critics': 1,\n  'net_arch': [],\n  'normalize_images': False,\n  'optimizer_class': torch.optim.adam.Adam,\n  'optimizer_kwargs': None,\n  'share_features_extractor': True},\n 'replay_buffer_class': None,\n 'replay_buffer_kwargs': None,\n 'seed': 42,\n 'tau': 0.005,\n 'tensorboard_log': 'logs/tb_logs',\n 'train_freq': (1, 'episode'),\n 'verbose': 1}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'callback': <Algorithms.learn.callbacks.ReportCallbacks at 0x272fd83a580>,\n 'eval_env': <Env.env.BSMarket at 0x272c75bd3d0>,\n 'eval_freq': 30,\n 'eval_log_path': 'logs/tb_logs/ddpg_220521-2355_1',\n 'log_interval': 30,\n 'n_eval_episodes': 1,\n 'reset_num_timesteps': True,\n 'tb_log_name': 'ddpg_220521-2355',\n 'total_timesteps': 500}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_kwargs['env']: <BSMarket instance>\n",
      "learn_kwargs['eval_env']: <BSMarket instance>\n",
      "learn_kwargs['tb_log_name']: ddpg_220522-0031\n",
      "learn_kwargs['eval_log_path']: logs/tb_logs/ddpg_220522-0031_1\n"
     ]
    }
   ],
   "source": [
    "env_kwargs['n_assets'] = 5\n",
    "\n",
    "learn_kwargs.update({\n",
    "    'total_timesteps': 100,\n",
    "})\n",
    "\n",
    "model_kwargs.update({\n",
    "    'buffer_size': 50,\n",
    "    'learning_starts': 30,\n",
    "})\n",
    "\n",
    "reconstruct_config(env_kwargs, model_kwargs, learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs['env'].n_assets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'callback': <Algorithms.learn.callbacks.ReportCallbacks at 0x272fd83a580>,\n 'eval_env': <Env.env.BSMarket at 0x272c6c77d30>,\n 'eval_freq': 30,\n 'eval_log_path': 'logs/tb_logs/ddpg_220522-0031_1',\n 'log_interval': 30,\n 'n_eval_episodes': 1,\n 'reset_num_timesteps': True,\n 'tb_log_name': 'ddpg_220522-0031',\n 'total_timesteps': 100}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.double_ddpg import DDPG\n",
    "\n",
    "model = DDPG(**model_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to logs/tb_logs\\ddpg_220522-0031_1\n",
      "[Training Start]\n",
      "Eval num_timesteps=30, episode_reward=-0.55 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.555   |\n",
      "| time/              |          |\n",
      "|    total timesteps | 30       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=60, episode_reward=-0.50 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.501   |\n",
      "| time/              |          |\n",
      "|    total timesteps | 60       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=90, episode_reward=-0.59 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.587   |\n",
      "| time/              |          |\n",
      "|    total timesteps | 90       |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.273    |\n",
      "|    critic2_loss    | 0.0394   |\n",
      "|    critic_loss     | 0.0181   |\n",
      "|    learning_rate   | 0.00199  |\n",
      "|    n_updates       | 5        |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120, episode_reward=-0.47 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 30       |\n",
      "|    mean_reward     | -0.468   |\n",
      "| time/              |          |\n",
      "|    total timesteps | 120      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.292    |\n",
      "|    critic2_loss    | 0.0113   |\n",
      "|    critic_loss     | 0.00775  |\n",
      "|    learning_rate   | 0.00125  |\n",
      "|    n_updates       | 10       |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "[Training End]  steps: 120\ttimes: 9.402783393859863\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Algorithms.double_ddpg.DDPG at 0x272fd818af0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(**learn_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
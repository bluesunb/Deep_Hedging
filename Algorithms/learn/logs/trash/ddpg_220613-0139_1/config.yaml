env_kwargs:
  cost: 0.02
  dividend: 0.0
  drift: 0.0
  freq: 1
  gen_name: gbm
  init_price: 1.0
  n_assets: 1000
  n_periods: 30
  payoff: european
  payoff_coeff: 1.0
  period_unit: 365
  reward_fn: entropy
  reward_fn_kwargs: {}
  reward_mode: pnl
  risk_free_interest: 0.0
  strike: 1.0
  volatility: 0.2
kwargs: {}
learn_kwargs:
  callback: !!python/name:Algorithms.ddpg.callbacks.ReportCallbacks ''
  eval_env: !!python/name:Env.env.BSMarketEval ''
  eval_freq: 30
  eval_log_path: ../logs/tb_logs/ddpg_220613-0139_1
  log_interval: 30
  n_eval_episodes: 1
  reset_num_timesteps: true
  tb_log_name: ddpg_220613-0139
  total_timesteps: 2000
model_kwargs:
  action_noise: !!python/object:stable_baselines3.common.noise.NormalActionNoise
    _mu: 0.0
    _sigma: 0.1
  batch_size: 15
  buffer_size: 300
  create_eval_env: false
  device: auto
  env: !!python/name:Env.env.BSMarket ''
  gamma: 0.99
  gradient_steps: -1
  learning_rate: !!python/name:Algorithms.ddpg.config.lr_schedule ''
  learning_starts: 300
  optimize_memory_usage: false
  policy: !!python/name:Algorithms.ddpg.policies.DoubleDDPGPolicy ''
  policy_kwargs:
    activation_fn: &id001 !!python/name:torch.nn.modules.activation.ReLU ''
    actor_net_kwargs: null
    critic_net_kwargs: null
    features_extractor_class: !!python/name:Env.feature_extractor.MarketObsExtractor ''
    features_extractor_kwargs:
      activation_fn: *id001
      features_in: 4
      features_out: 2
      last_activation_fn: *id001
      net_arch:
      - 32
      - 64
    n_critics: 1
    net_arch: []
    normalize_images: false
    ntb_mode: false
    optimizer_class: !!python/name:torch.optim.adam.Adam ''
    optimizer_kwargs: null
    share_features_extractor: true
  replay_buffer_class: !!python/name:Env.buffers.CustomReplayBuffer ''
  replay_buffer_kwargs: {}
  seed: 42
  tau: 0.005
  tensorboard_log: ../logs/tb_logs
  train_freq: !!python/tuple
  - 1
  - episode
  verbose: 1
